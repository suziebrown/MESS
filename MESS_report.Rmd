---
title: "Modelling the MESS Data"
author: "Suzie Brown and Marco Palma"
date: "1 November 2017"
output: pdf_document
bibliography: MESSbib.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, fig.align="center", warning=FALSE)

library(knitr)
library(survival)
library(timereg)
library(dplyr)
library(randomForestSRC)
library(ggRandomForests)
#library(flexsurv)
#library(plotmo)
```


# Introduction

Th MESS data comes from a randomised controlled trial about treatments for epilepsy. The subjects in the study are patients who have had only one seizure or hve not had epilepsy for long. There are two treatments; either immediate or deferred. Patients assigned the deferred treatment are not prescribed anti-epileptic drugs after their first seizure, but the decision is revisited if they have further seizures.

Because many people have only one seizure in their life, we don't necessarily want to put patients on anti-epileptic drugs after just one seizure. However, we also don't want patients going on to have further seizures that could have been prevented or reduced by starting treatment immediately.

We are therefore interested in the level of benefit associated with immediate treatment relative to deferred treatment. Ultimately we could weigh this up against the costs of ongoing medication in order to decide whether a new patient should be given immediate treatment or not. This decision could depend on other data about the patient; for instance the trial recorded demographic details, results of some medical tests, and information about previous seizures.

Our aim is to construct a model considering some of these factors, which can be used to predict the outcome for a specific type of patient under immediate and deferred treatment. The model could then be used with some loss function to make optimal decisions about how to treat new patients.

# Exploratory analysis 

```{r}
mess <- read.csv("MESSdat.csv", sep="\t", header=T)
```

### Change data types

We first format as factors those variables that should be factors, format the dates as dates, and change the 1/2-coded binary variables to 0/1.
```{r}
#Treatment 0/1 and sex 0/1 have been stored as numeric; we change the data type to factor.
mess$trt<-as.factor(mess$trt)
mess$sex<-as.factor(mess$sex)
```

```{r}
#We see that there are many NAs in the columns relating to dates, but this is not shown on the summary because they are formatted as character. We format the dates as dates.
mess$d1sp<-as.Date(mess$d1sp,"%d/%m/%y")
mess$d1cp<-as.Date(mess$d1cp,"%d/%m/%y")
mess$d1ps<-as.Date(mess$d1ps,"%d/%m/%y")
mess$d1myo<-as.Date(mess$d1myo,"%d/%m/%y")
mess$d1ab<-as.Date(mess$d1ab,"%d/%m/%y")
mess$d1aab<-as.Date(mess$d1aab,"%d/%m/%y")
mess$d1tc<-as.Date(mess$d1tc,"%d/%m/%y")
mess$d1oth<-as.Date(mess$d1oth,"%d/%m/%y")
mess$d1seiz<-as.Date(mess$d1seiz,"%d/%m/%y")
mess$rand<-as.Date(mess$rand,"%d/%m/%y")
```

```{r, results='hide'}
#We assume the `centre` variable must be an identifying number for the clinic where the subject entered the trial. As such, we format it as a factor.
table(mess$centre)
mess$centre <- as.factor(mess$centre)
# maybe include in the model, by grouping them together? but it's a bit arbitrary - would be nice to know if the numbers are related to geographical location.
```

```{r}
#We find that the binary results for the various medical tests have been stored as 1/2 = yes/no. We convert these to 0/1 = no/yes.
# as.logical ?
mess$eeg <- as.factor(ifelse(mess$eeg==2,0,mess$eeg))
mess$abeeg <- as.factor(ifelse(mess$abeeg==2,0,mess$abeeg))
mess$nsab <- as.factor(ifelse(mess$nsab==2,0,mess$nsab))
mess$gparsp <- as.factor(ifelse(mess$gparsp==2,0,mess$gparsp))
mess$gparnsp <- as.factor(ifelse(mess$gparnsp==2,0,mess$gparnsp))
mess$fparsp <- as.factor(ifelse(mess$fparsp==2,0,mess$fparsp))
mess$fparnsp <- as.factor(ifelse(mess$fparnsp==2,0,mess$fparnsp))
mess$swab <- as.factor(ifelse(mess$swab==2,0,mess$swab))
```

### Check censoring indicator

Next we want to see which way round the censoring indicator is used. We see that where the censoring indicator `ind1yr` is 1, the time to one year remission `int1yr` has minimum 365, whereas where `ind1yr` is 0, the minimum is 1. From this we deduce that the indicator is 1 when the variable is observed and 0 if the variable is censored.
```{r, results='hide'}
summary(mess$int1yr[mess$ind1yr==1])
summary(mess$int1yr[mess$ind1yr==0])
```

### Missing data

We verify that the same data are missing from `d1seiz` and `period`. These were probably subjects who couldn't remember the date of their first seizure, and/or whose medical records were missing. This suggests they are missing not at random - for instance if the subject can't remember the date it is likely to be a long time ago, i.e. higher values of `period`. However, since they are only 5 out of 1425 observations, we suspect it will not make much difference to treat them as if missing at random.
```{r, results='hide'}
all.equal(which(is.na(mess$d1seiz)),which(is.na(mess$period)))
```

### Investigate some variables

Plotting the age at randomisation `ager` we see that it is positively skewed. This is plausible since it is a study of people with single seizure or recent diagnosis of epilepsy, and it is more likely that an individual has their first seizure at a younger age.
```{r, out.width = "50%"}
hist(mess$ager,breaks=20, col="grey", xlab="age at randomisation", main="")
```

We see that the number of subjects having each treatment is roughly equal, in accordance with the design of the study.
```{r}
t.trt <- table(mess$trt)
dimnames(t.trt) <- list(treatment=c("Immediate","Deferred"))
t.trt
```

There is a mystery as to how some patients who have not had an EEG have recorded an abnormal EEG result. There are several possible explanations (different types of recording error), but we will assume the patients with an abnormal EEG have had an EEG. We adjust the `eeg` varaible accordingly. Since there are only five subjects in this category it shoudln't substantially affect any results.
```{r}
t.eeg <- table(mess$eeg,mess$abeeg)
dimnames(t.eeg) <- list(EEG=c(0,1), abEEG=c(0,1))
t.eeg

mess$eeg[mess$eeg==0 & mess$abeeg==1] <- 1
```

### Split age into bins

We use the age categories referred to in @marson2005.
```{r}
mess$agecat <- cut(mess$ager,c(0,5,9,19,29,39,49,59,69,max(mess$ager)),include.lowest = T)
t.agec <- table(mess$agecat)
dimnames(t.agec) <- list(agecategory=levels(mess$agecat))
t.agec
```

### Transform some variables

We plotted histograms of each of the key (non-binary) variables. The variables `nseiz` and `period` are very positively-skewed. This is not surprising since this is a study on early epilepsy, so most subjects have only had one seizure and the first seizure was not long before entering the study.
```{r}
par(mfrow=c(2,2))
hist(mess$intseiz1, breaks=20, col="grey", main="", xlab="time to first seizure post-r.")
hist(mess$ager, breaks=20, col="grey", main="", xlab="age")
hist(mess$nseiz, breaks=20, col="grey", main="", xlab="number of previous seizures")
hist(mess$period, breaks=20, col="grey", main="", xlab="time since first seizure pre-r.")
```
We will try transforming `period` and `nseiz`. For `nseiz`, we simply use the indicator of whether it is 1 or more than 1, since over half of the patients have `nseiz==1`. We take the logarithm of `period` to reduce the skew.

```{r, results='hide', fig.keep='none'}
#par(mfrow=c(1,2))
mess$period.tr <- log(mess$period + 1)
mess$nseiz.tr <- mess$nseiz > 1
hist(mess$period.tr, breaks = 20, col="grey")
#hist(mess$nseiz.tr)
```

## Select initial set of covariates

For the purposes of the initial exploratory model fitting, we use a small subset of the covariates. We address the issue of variable selection later on.

We drop all of the date variables because we suspect the absolute time does not matter; relative times are available for many of the events. We also drop the sub-categories for different types of seizures, retaining just the number of tonic-clonic seizures (the most severe type) and the overall number of seizures. We also drop the sub-categories of EEG abnormality, retaining just the overall indicator. We do not include the centre, since there are so many levels it adds too many degrees of freedom, and we have no information about how they might be grouped e.g. geographically.
```{r, echo=TRUE}
covars1 <- transmute(mess, ager, sex, trt, ntc, nseiz.tr, period.tr, eeg, abeeg)
```


# Check balance of randomisation

We check that the randomisation is balanced over sex and age. There is a noticeable deviation from an even split in some categories, but the deviation is not systematic and the overall sample size is large so it should not make a big difference to our results.
```{r, out.width="70%"}
t.sex <- table(mess$sex,mess$trt)
colnames(t.sex)<-c('immediate','deferred')
rownames(t.sex)<-c('male','female')
plot(t.sex, main="randomisation by sex", ylab="treatment", xlab='')
text(0.25,0.75,t.sex[1,1])
text(0.75,0.75,t.sex[2,1])
text(0.25,0.25,t.sex[1,2])
text(0.75,0.25,t.sex[2,2])

t.age <- table(mess$agecat, mess$trt)
colnames(t.age)<-c('immediate','deferred')
plot(t.age, main="randomisation by age", ylab="treatment", xlab='')
```


# Exploratory Kaplan-Meier curves

We plot Kaplan-Meier curves of the first seizure after randomisation, grouped by treatment and sex. The first plot shows that the survival probability for those who received a deferred treatment is lower than for those immediately treated, at least for the first 5 years after the randomisation. From the second plot it seems that sex does not have a significant effect on the survival probability.
```{r}
surv1 <- with(mess, Surv(intseiz1, indseiz1 == 1))
mfit <- survfit(surv1 ~ 1, conf.type = "log-log", data = mess)
#options(survfit.print.mean =T)
#plot(mfit, mark.time=T, xlab =factor(c(1,1)) "Days since randomisation",ylab = "Survival")
#summary(mfit,censored=T)
par(mfrow=c(1,2))
n.years <- seq(365.25, max(mess$intseiz1), by=365.25)
mfit.trt <- survfit(surv1 ~ trt,  data = mess)  #conf.type = "log-log",
plot(mfit.trt, conf.int = T, mark.time=F, col =  2:3, xlab = "Years since randomisation", ylab = "Survival probability" ,xscale = 365.25, cex=0.8)#,xaxt = 'n')
#axis(side=1, at=n.years,labels = 1:length(n.years))
legend("topright", legend = c("Immediate","Deferred"), col = 2:3, lty=1)
mfit.sex <- survfit(surv1 ~ sex, conf.type = "log-log", data = mess)
plot(mfit.sex, conf.int = T, mark.time=F, col = c("orange","brown"), xlab = "Years since randomisation",ylab = "Survival probability",xscale = 365.25, cex=0.8)#,xaxt = 'n')
#axis(side=1, at=n.years,labels = 1:length(n.years))
legend("topright", legend = c("Male","Female"), col = c("orange","brown"), lty=1)

#plot(mfit.trt, mark.time = FALSE, fun = "cloglog")
#lfit <- survreg(surv1 ~ trt, data=mess)
#pct <- 1:98/100   # The 100th percentile of predicted survival is at +infinity
#ptime <- predict(lfit, newdata=mess, type='quantile',p=pct, se=TRUE)
#matplot(ptime$fit, 1-pct,xlab="Months", ylab="Survival", type='l', lty=c(1,2,2), col=1)
```


# Cox proportional hazards model

The Cox model relies on the strong assumption of *proportional hazards*, that is that a unit increase in a certain covariate has a multiplicative effect on the hazard rate. In particular, the hazard function $\lambda$ has the form
$$\lambda(t|X) = \lambda_0(t)\exp{(X^T \beta)}$$
where $X$ is the matrix of covariates and $\beta$ is the vector of coefficients to be estimated, and $\lambda_0(t)$ is the baseline hazard (i.e. when all covariates are zero). The exponential of a coefficient $\exp(\beta_i)$ represents the multiplicative effect on the hazard resulting from a unit increase in the corresponding covariate.

First we fit a naive proportional hazards model with the covariates of interest. We see that the treatment `trt` is significant, as is the number `nseiz` of seizures prior to entering the study. This is to be expected since subjects with a tendency for more frequent seizures are likely to go less time before the first post-randomisation seizure regardless of treatment. The elapsed time `period` between the subject's first seizure and their entry into the trial is slightly significant, which is also unsurprising.

Next we assess whether proportional hazards is a suitable assumption for these data. We see from the residual plots that the treatment seems to have a decreasing effect over time and the residuals have mean consistently greater than zero. The residuals of the other covariates don't seem to vary over time. This is confirmed by the small p-value for `trt` in the test of the proportional hazards assumption. The treatment effect decreasing over time is indicative that a proportional hazards model is not suitable, but we will try a few fixes before abandoning the Cox model completely.

```{r, out.width="70%"}
mycox <- coxph(Surv(mess$intseiz1,mess$indseiz1,type="right") ~ trt + ager + sex + nseiz + period, data=mess)
kable(cbind(summary(mycox)$coefficients[,c(1,2,5)],print(cox.zph(mycox))[-nrow(print(cox.zph(mycox))),3]), digits = 3, col.names=c("coef","exp(coef)","p.coef","p.PH"))
plot(cox.zph(mycox)[1,])
```

Next we try adding into the model an interaction term of treatment with time, to correct for the problem with the first model. We see, as expected, that the interaction term is very significant. However the proportional hazards model is still rejected.

```{r}
mycox2 <- coxph(Surv(mess$intseiz1,mess$indseiz1,type="right") ~ trt + ager + sex + nseiz + period + trt:intseiz1, data=mess)
kable(cbind(summary(mycox2)$coefficients[,c(1,2,5)],print(cox.zph(mycox2))[-nrow(print(cox.zph(mycox2))),3]), digits = 3, col.names=c("coef","exp(coef)","p.coef","p.PH"))
#cox.zph(mycox2)
```

Next we fit the model using the transformed versions of `period` and `nseiz`. The significant covariates are largely the same as in the first model, however the assumption of proportional hazards is not supported in the `trt` and `nseiz` terms.

```{r}
mycox3 <- coxph(Surv(mess$intseiz1,mess$indseiz1,type="right") ~ trt + ager + sex + nseiz.tr + period.tr, data=mess)
kable(cbind(summary(mycox3)$coefficients[,c(1,2,5)],print(cox.zph(mycox3))[-nrow(print(cox.zph(mycox3))),3]), digits = 3, col.names=c("coef","exp(coef)","p.coef","p.PH"))
#cox.zph(mycox3)
```

Finally, in the next model we include an interaction term between `trt` and `nseiz`, since it is plausible that the treatment may have a different effect on people who suffer more severely (indicated by having had more seizures previously). With this model the proportional hazards assumption appears to be satisfied. However we find that the interaction term is only slightly significant, and including the interaction drastically reduces the estimated treatment effect.

```{r}
mycox4 <- coxph(Surv(mess$intseiz1,mess$indseiz1,type="right") ~ trt + ager + sex + nseiz.tr + period.tr + trt:nseiz.tr, data=mess)
kable(cbind(summary(mycox4)$coefficients[,c(1,2,5)],print(cox.zph(mycox4))[-nrow(print(cox.zph(mycox4))),3]), digits = 3, col.names=c("coef","exp(coef)","p.coef","p.PH"))
#cox.zph(mycox4)
```

.............PROPORTIONAL HAZARDS ASSUMPTION FAILS: SHOW TEST AND PLOTS..................

# Aalen's additive model

The proportional hazards assumption underlying Cox model might be in many cases too strict and lead to unrealistic conclusions. Moreover, it is not uncommon to consider that the effect of one or more covariates might change over time. In these cases the model proposed by @aalen1989linear provides a flexible way to tackle these issues. Unlike Cox model, in Aalen's model the effect of the covariate on the hazard function at time t is additive. In other words, the hazard function at time t is a linear function of the covariates. Each coefficient is a function allowed to vary over time; in this sense, the model is fully nonparametric. At time t, the value of the coefficient function is to be read as the variation with respect to the baseline hazard function induced by a change of one unit (level in case of categorical variables) in the covariates. 

Aalen's additive model is widely used because of the easiness in the interpretation of the graphical results, that report the cumulative regression coefficient over time with 95% confidence bands. The slope of the cumulative coefficient function gives indeed some information about the effect of a variable on the outcome of interest.<!-- When the effect of the covariate is constant over time (like in Cox model), the cumulative regression coefficient will look like a straight line; on the contrary, if the effect becomes null only after a certain time point, the slope of the cumulative regression coefficient will decrease towards zero. When the covariate does not play a role in explaining the variability in the hazard function, the value 0 will be included in the confidence bands for all the time interval. -->
For what concerns the effect of deferring the treatment, the cumulative coefficient increases in the first two years approximately after randomisation, then remains flat: this suggests that the hazard ratio is fairly stable until that breakpoint and then it gets closer to 1. In other words, after two years having received the treatment immediately or not has no effect on the time to the next seizure. A similar conclusion can be drawn on the number of seizures pre-randomisation. In addition, the time from the last seizure .... .......... has not a significant effect after approximately 2 years, while the effect of an abnormal EEG is quite constant over time

```{r}
modaalen<-aalen(surv1 ~ trt + const(ager) + const(sex) + const(nseiz) + const(period) + const(abeeg), data = mess , n.sim=100)
#summary(modaalen)
#par(mfrow=c(3,3))
#plot(modaalen)
modaalen2<-aalen(surv1 ~ trt + const(ager) + sex + nseiz.tr + period.tr + abeeg , data = mess , n.sim=100)
#modaalen3<-aalen(surv1 ~ . - ager + const(ager), data = covars , n.sim=100)
#x11()
par(mfrow=c(2,2))
#c(2,4,5,6)
titles <- c("NA","Deferred treatment (1)", "NA","Number of seizures > 1", "Period from last seizure (log)", "Abnormal EEG")
for (i in c(2,4,5,6)){
plot(modaalen2, specific.comps = i, xlab = "Time (in days)", mains = F)
title(main = titles[i])
if(i %in% c(4,5)) mtext("Pre-randomisation",cex = 0.75, line = 0.5)
}
#axis(side=1, at=n.years,labels = 1:length(n.years))
#dev.off()
#plot(modaalen2)
```

# Parametric survival models

An alternative to the Cox model is to consider a parametric specification for the distribution of survival times. In particular, the class of accelerated failure time (AFT) models provides the natural extension in case the proportional hazard assumption does not work. Following the introduction provided by @hosmer2008applied, it is possible to write the distribution of the time to event for the $i$-th subject as 
$$\log(t_i)=\mu+\beta^T x_i+\sigma \epsilon_i $$

 where $\sigma$ is a scale parameter and $\epsilon_i$ is an error term with a prespecified distribution (its choice determines the type of model). <!--Common choices for the regression models are exponential, Weibull, lognormal (when the distribution of $\epsilon$ and therefore the distribution of $ln(t)$ is normal) and loglogistic: this choice will affect the shape of the hazard function, that may be monotonic or having a maximum dependent on the scale parameter.   --> The effects in this model are multiplicative on the time scale: in other words, the time to the event depends on the exponential of the linear combination of the covariates weighted by the coefficients. The name “accelerated failure time” arises from the fact that given
$$ t_i=\exp{[\beta^Tx_i]}\exp{[\sigma\epsilon_i]} $$
the effect of the covariates is to “accelerate” or decelerate the time to the event of interest with respect to a subject with baseline characteristics (i.e., the one for which all the covariates assume value zero). This means that if for a given variable the coefficient is positive, the time to the event will increase, hence the effect of the covariate will be protective. Therefore, the sign of the coefficient has to be read in opposite way with respect to the proportional hazards models.

In this report we proposed 4 parametric regression models: exponential, Weibull, lognormal (where $\epsilon$ and therefore $ln(t)$ are normally distributed) and loglogistic. The same set of covariates has been used for all of them: namely, `trt`, `sex`, `age`, `nseiz.tr`,`period.tr`, `abeeg`. The selection of the most suitable parametric form is done on the basis of the lowest AIC, that is reached by the lognormal model among the accelerated failure time (AFT) ones considered.


```{r, results='hide'}
# modpar1 <- survreg(surv1 ~ trt + ager + sex + nseiz + period + abeeg, mess, dist="exponential")
# summary(modpar1)
# modpar2 <- survreg(surv1 ~ trt + ager + sex + nseiz + period + abeeg, mess, dist="weibull")
# summary(modpar2)
# modpar3 <- survreg(surv1 ~ trt + ager + sex + nseiz + period + abeeg, mess, dist="lognormal")
# summary(modpar3)
# modpar4 <- survreg(surv1 ~ trt + ager + sex + nseiz + period + abeeg, mess, dist="loglogistic")
# summary(modpar4)

# modpar1 <- flexsurvreg(surv1 ~ trt + ager + sex + nseiz + period, data = mess, dist="weibull")
# summary(modpar1)
# modpar2 <- flexsurvreg(surv1 ~ trt + ager + sex + nseiz + period, data = mess, dist="lnorm")
# summary(modpar2)
# modpar3 <- flexsurvreg(surv1 ~ trt + ager + sex + nseiz + period, data = mess, dist="llogis")
# summary(modpar3)
# modpar5 <- flexsurvreg(surv1 ~ trt + ager + sex + nseiz + period, data = mess, dist="gengamma")
# summary(modpar5)

# parmodels<-matrix(NA,nrow=4,ncol=4)
# parmodels[1,] <- c(summary(modpar1)$n, modpar1$loglik[1],summary(modpar1)$df, AIC(modpar1))
# parmodels[2,] <- c(summary(modpar2)$n, modpar2$loglik[1],summary(modpar2)$df, AIC(modpar2))
# parmodels[3,] <- c(summary(modpar3)$n, modpar3$loglik[1],summary(modpar3)$df, AIC(modpar3))
# parmodels[4,] <- c(summary(modpar4)$n, modpar4$loglik[1],summary(modpar4)$df, AIC(modpar4))
# colnames(parmodels) <- c("N.obs","Loglik","df","AIC")
# rownames(parmodels) <- c("exponential","weibull","lognormal","loglogistic")
# #parmodels
# kable(parmodels, digits=3)
```


```{r}
## Now let us consider the transformed variables.
modpar1.tr <- survreg(surv1 ~ trt + scale(ager,scale = F) + sex + nseiz.tr + period.tr + abeeg, mess, dist="exponential")
modpar2.tr <- survreg(surv1 ~ trt + scale(ager,scale = F) + sex + nseiz.tr + period.tr + abeeg, mess, dist="weibull")
modpar3.tr <- survreg(surv1 ~ trt + scale(ager,scale = F) + sex + nseiz.tr + period.tr + abeeg, mess, dist="lognormal")
modpar4.tr <- survreg(surv1 ~ trt + scale(ager,scale = F) + sex + nseiz.tr + period.tr + abeeg, mess, dist="loglogistic")

parmodels.tr<-matrix(NA,nrow=4,ncol=4)
parmodels.tr[1,] <- c(summary(modpar1.tr)$n, modpar1.tr$loglik[1],summary(modpar1.tr)$df, AIC(modpar1.tr))
parmodels.tr[2,] <- c(summary(modpar2.tr)$n, modpar2.tr$loglik[1],summary(modpar2.tr)$df, AIC(modpar2.tr))
parmodels.tr[3,] <- c(summary(modpar3.tr)$n, modpar3.tr$loglik[1],summary(modpar3.tr)$df, AIC(modpar3.tr))
parmodels.tr[4,] <- c(summary(modpar4.tr)$n, modpar4.tr$loglik[1],summary(modpar4.tr)$df, AIC(modpar4.tr))
colnames(parmodels.tr) <- c("N.obs","Loglik","df","AIC")
rownames(parmodels.tr) <- c("exponential","weibull","lognormal","loglogistic")  
#parmodels.tr #the difference to be interpreted in terms of chisq(1) = 3.84 
kable(parmodels.tr, digits = 3)
```

Once the parametric form has been established, we might consider to include other covariates in the model in order to discover whether they may have an influence on the phenomenon under study. In particular, we fitted a new lognormal model by adding to the previous set of covariates all the variables referring to the type of seizures experienced before randomization (`nsp`, `nps`, `nps`, `nmyo`, `nab`, `naab`, `ntc`, `noth`) and the type of EEG abnormality (`nsab`, `gparsp`, `gparnsp`, `fparsp`, `fparnsp`). In addition, we insert an interaction term between the treatment and the number of seizures pre-randomisation.

ARE WE INTERESTED IN EEG? 
```{r}
covars <- transmute(mess, ager, sex, trt, nsp, ncp, nps, nmyo, nab, naab, ntc, noth, nseiz.tr, period.tr, eeg, abeeg, nsab, gparsp, gparnsp, fparsp, fparnsp)  ###swab removed because it gives errors

###Double check that the lognormal is the best
# a1<-survreg(surv1 ~ . + trt:nseiz.tr , covars, dist="exponential") 
# a2<-survreg(surv1 ~ . + trt:nseiz.tr , covars, dist="weibull") 
# a3<-survreg(surv1 ~ . + trt:nseiz.tr , covars, dist="lognormal") 
# a4<-survreg(surv1 ~ . + trt:nseiz.tr , covars, dist="loglogistic")
# which.min(c(AIC(a1),AIC(a2),AIC(a3),AIC(a4)))

modpar.logn <- survreg(surv1 ~ . + trt:nseiz.tr , covars, dist="lognormal")
modpar.signif <- summary(modpar.logn)$table[,4]<=0.05
kable(summary(modpar.logn)$table[modpar.signif,], digits = 3)
```

We point out that many of the variables included in the model (especially those referring to an EEG abnormality) seems to be not significant. 
SOMETHING TO LINK THIS PARAGRAPH AND THE NEXT ONE.

```{r, include=FALSE}
## Survival Lasso
# 
# XX <- model.matrix(Surv(mess$intseiz1, mess$indseiz1, type="right") ~ ager + sex + trt + nsp + ncp + nps + nmyo + nab + naab + ntc + noth + nseiz.tr + period.tr + eeg + abeeg + nsab + gparsp + gparnsp + fparsp + fparnsp + swab, data=mess)
# 
# YY=Surv(mess$intseiz1, mess$indseiz1, type="right")
# YY <- YY[complete.cases(covars),] #remove rows with missing values (there are only 5/1425)
# 
# mynet <- glmnet(x=XX, y=YY, family="cox")
# mycvnet <- cv.glmnet(x=XX, y=YY, family="cox")
# 
# plot_glmnet(mynet, s=mycvnet$lambda.min)
```


# Random survival forests

We would like to ensure that the set of covariates we include in the model is relatively stable. Up to now we have only selected covariates insofar as the fitted log-normal model has some significant and some insignificant covariates. We now compare the set of significant covariates in the log-normal model to those obtained using a non-parametric variable selection technique, namely random survival forests.

Again we omit the `centre` variable since it destabilises the model, having a large number of levels many of which correspond to only one observation. If we had some additonal information say about suitably groupings of centres it would be sensible to include it. For instance, in @marson2005 the authors distinguish between UK and non-UK centres. However we do not have any information linking the number of a centre to its location. However we now inlcude the counts of every type of seizure, and the results of all tests, as possible covariates. 

We still omit date variables. we found that the error rate didn't really decrease by creating more than 100-200 trees, so we use `ntree = 200`. There is not a universal threshold on the `vimp` above which variables should be considered selected, but in the literature `vimp=0.002` has been suggested as a rule-of-thumb.
```{r, cache=TRUE, out.width="60%"}
rsf.surv1<-rfsrc(Surv(intseiz1, indseiz1, type="right") ~ ager + sex + trt + nsp + ncp + nps + nmyo + nab + naab + ntc + noth + nseiz.tr + period.tr + eeg + abeeg + nsab + gparsp + gparnsp + fparsp + fparnsp + swab, data=mess, ntree = 200, importance=TRUE,  tree.err = T)

#print(rsf.surv1)
#plot(rsf.surv1)
gg_dta <- gg_vimp(rsf.surv1)
plot(gg_dta)
```

As we found in our exploratory analysis, `nseiz` and `trt` are the most important covariates, with `abeeg` also significant. We also see the counts of several particular types of seizure are important, which weren't included in our initial analysis.

The six most important variables in random forests were all significant in the log-normal model, which is encouraging. On the whole, random forests has selected roughly the same variables as the log-normal model, with only a few discrepancies. For instance, `nps` (one of the seizure counts) was significant in the log-normal model (p=0.009) but was not selected by random forests.

For the purposes of our model, we will include only the covariates which the parametric and non-parametric approaches have both selected, namely `nseiz`, `trt`, `ncp`, `nsp`, `abeeg`, and `nmyo`. This captures the most important covariates of each approach.


# Final model

Given a parametric specification for the model and a restricted set of covariates, we can fit the final model for the data at hand. PARSIMONIOUS MODEL

WHAT ABOUT PERIOD.TR?
```{r}
modpar.lognFINAL <- survreg(surv1 ~  trt + nseiz.tr + abeeg + ncp + nsp + nmyo + trt:nseiz.tr + period.tr , covars, dist="lognormal") 
kable(summary(modpar.lognFINAL)$table, digits = 3)
```

SCALE PARAMETER LARGER THAN 1

```{r}
modpar.lognFINAL$scale
```

FINAL CONSIDERATIONS ABOUT THE INTERPRETATION OF COEFFICIENTS.

PREDICTION FOR SOME SUBJECTS.
```{r}
###DFNEW NOT WORKING!
#dfNew <- data.frame(sex=factor(c(0,0)), trt=factor(c(0,1)),ager=84,nseiz.tr=factor(c(1,1)),period.tr = 3.4, abeeg = factor(c(1,1)))
#percs <- (1:99)/100
#FLogN <- predict(modpar3.tr, newdata=dfNew, type="quantile", p=percs, se=TRUE)
#matplot(cbind(FLogN$fit[1, ],
#              FLogN$fit[1, ] - 2*FLogN$se.fit[1, ],
#              FLogN$fit[1, ] + 2*FLogN$se.fit[1, ])/365.25, 1-percs,
#        type="l", main=expression(paste("LogNormal-Fit ", hat(S)(t), " with SE")),xlim = c(0,10),
#        xlab="Time (in years)", ylab="Survival", lty=c(1, 2, 2), lwd=2, col="blue")
#matlines(cbind(FLogN$fit[2, ],
#               FLogN$fit[2, ] - 2*FLogN$se.fit[2, ],
#               FLogN$fit[2, ] + 2*FLogN$se.fit[2, ])/365.25, 1-percs, col="red", lwd=2)
#legend(x="topright", lwd=2, lty=c(1, 2, 1, 2), col=c("blue", "blue", "red", "red"),
#       legend=c("Trt 1 (immediate)", "+- 2*SE", "Trt 0 (deferred)", "+- 2*SE"))
```

# Further research

SCALE PARAMETER DEPENDING ON TREATMENT

LOGISTIC AFTER 6 MONTHS, 1 YEAR...

FRAILTY MODELS (and consider centre effect)

TONIC CLONIC SEIZURES, 2ND AND 5TH SEIZURES...


JANE'S MODEL


## References
