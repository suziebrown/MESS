---
title: "Modelling the MESS Data"
author: "Suzie Brown and Marco Palma"
date: "26 October 2017"
output: pdf_document
bibliography: MESSbib.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(survival)
library(timereg)
library(dplyr)
library(randomForestSRC)
library(ggRandomForests)
#library(flexsurv)
#library(plotmo)
```


# Introduction

Th MESS data is from a randomised controlled trial about treatment for epilepsy. The subjects in the study are patients who have had only one seizure or hve not had epilepsy for long. There are two treatments; either immediate or deferred. Patients assigned the deferred treatment are not prescribed anti-epileptic drugs after their first seizure, but the decision is revisited if they have further seizures.

Because many people have only one seizure in their life, we don't necessarily want to put patients on anti-epileptic drugs after just one seizure. However, we also don't want patients going on to have further seizures that could have been prevented or reduced by starting treatment immediately.

We are therefore interested in the level of benefit associated with immediate treatment relative to deferred treatment. Ultimately we could weigh this up against the costs of ongoing medication in order to decide whether a new patient should be given immediate treatment or not. This decision could depend on other data about the patient; for instance the trial recorded demographic details, results of some medical tests, and information about previous seizures.

Our aim is to construct a model considering some of these factors, which can be used to predict the outcome for a specific type of patient under immediate and deferred treatment. The model could then be used with some loss function to make optimal decisions about how to treat new patients.

# Methods

## Aalen's additive model

The proportional hazards assumption underlying Cox model might be in many cases too strict and lead to unrealistic conclusions. Moreover, it is not ... to consider that the effect of one or more covariates might change over time. In these cases the model proposed by @aalen1989linear provides a flexible way to tackle these issues. Unlike Cox model, in Aalen's model the effect of the covariate on the hazard function at time t is additive. In other words, the hazard function at time t is a linear function of the covariates. Each coefficient is a function allowed to vary over time; in this sense, the model is fully nonparametric. At time t, the value of the coefficient function is to be read as the variation with respect to the baseline hazard function induced by a change of one unit (level in case of categorical variables) in the covariates. 
Aalen's additive model is widely used because of the easiness in the interpretation of the graphical results, that report the cumulative regression coefficient over time with 95% confidence bands. When the effect of the covariate is constant over time (like in Cox model), the cumulative regression coefficient will look like a straight line; on the contrary, if the effect becomes null only after a certain time point, the slope of the cumulative regression coefficient will decrease towards zero. When the covariate does not play a role in explaining the variability in the hazard function, the value 0 will be included in the confidence bands for all the time interval.

## Parametric survival models





# Data wrangling

```{r}
mess <- read.csv("MESSdat.csv", sep="\t", header=T)
```

## Change data types

Treatment 0/1 and sex 0/1 have been stored as numeric; we change the data type to factor.
```{r}
mess$trt<-as.factor(mess$trt)
mess$sex<-as.factor(mess$sex)
```

We see that there are many NAs in the columns relating to dates, but this is not shown on the summary because they are formatted as character. We first format the dates as dates.
```{r}
mess$d1sp<-as.Date(mess$d1sp,"%d/%m/%y")
mess$d1cp<-as.Date(mess$d1cp,"%d/%m/%y")
mess$d1ps<-as.Date(mess$d1ps,"%d/%m/%y")
mess$d1myo<-as.Date(mess$d1myo,"%d/%m/%y")
mess$d1ab<-as.Date(mess$d1ab,"%d/%m/%y")
mess$d1aab<-as.Date(mess$d1aab,"%d/%m/%y")
mess$d1tc<-as.Date(mess$d1tc,"%d/%m/%y")
mess$d1oth<-as.Date(mess$d1oth,"%d/%m/%y")
mess$d1seiz<-as.Date(mess$d1seiz,"%d/%m/%y")
mess$rand<-as.Date(mess$rand,"%d/%m/%y")
```

We assume this variable must be an identifying number for the clinic where the subject entered the trial. As such, we format it as a factor.
```{r}
table(mess$centre)
mess$centre <- as.factor(mess$centre)
# maybe include in the model, by grouping them together? but it's a bit arbitrary - would be nice to know if the numbers are related to geographical location.
```

We find that the binary results for the various medical tests have been stored as 1/2 = yes/no. We convert these to 0/1 = no/yes.
```{r}
# as.logical ?
mess$eeg <- as.factor(ifelse(mess$eeg==2,0,mess$eeg))
mess$abeeg <- as.factor(ifelse(mess$abeeg==2,0,mess$abeeg))
mess$nsab <- as.factor(ifelse(mess$nsab==2,0,mess$nsab))
mess$gparsp <- as.factor(ifelse(mess$gparsp==2,0,mess$gparsp))
mess$gparnsp <- as.factor(ifelse(mess$gparnsp==2,0,mess$gparnsp))
mess$fparsp <- as.factor(ifelse(mess$fparsp==2,0,mess$fparsp))
mess$fparnsp <- as.factor(ifelse(mess$fparnsp==2,0,mess$fparnsp))
mess$swab <- as.factor(ifelse(mess$swab==2,0,mess$swab))
```

## Check censoring indicator

Next we want to see which way round the censoring indicator is used. We see that where the censoring indicator `ind1yr` is 1, the time to one year remission `int1yr` has minimum 365, whereas where `ind1yr` is 0, the minimum is 1. From this we deduce that the indicator is 1 when the variable is observed and 0 if the variable is censored.
```{r}
summary(mess$int1yr[mess$ind1yr==1])
summary(mess$int1yr[mess$ind1yr==0])
```

## Missing data

We verify that the same data are missing from `d1seiz` and `period`. These were probably subjects who couldn't remember the date of their first seizure, and/or whose medical records were missing. This suggests they are missing not at random - for instance if the subject can't remember the date it is likely to be a long time ago, i.e. higher values of `period`. However, since they are only 5 out of 1425 observations, we suspect it will not make much difference to treat them as if missing at random.
```{r}
all.equal(which(is.na(mess$d1seiz)),which(is.na(mess$period)))
```

## Investigate some variables

Plotting the age at randomisation `ager` we see that it is positively skewed. This is plausible since it is a study of people with single seizure or recent diagnosis of epilepsy, and it is more likely that an individual has their first seizure at a younger age.
```{r}
hist(mess$ager,breaks=20)
```

We see that the number of subjects having each treatment is roughly equal, as was the design of the study.
```{r}
table(mess$trt)
```

There is a mystery as to how some patients who have not had an EEG have recorded an abnormal EEG result. There are several possible explanations (different types of recording error), but we will assume the patients with an abnormal EEG have had an EEG. We adjust the `eeg` varaible accordingly. Since there are only five subjects in this category it shoudln't substantially affect any results.
```{r}
t.eeg <- table(mess$eeg,mess$abeeg)
dimnames(t.eeg) <- list(EEG=c(0,1), abEEG=c(0,1))
t.eeg

mess$eeg[mess$eeg==0 & mess$abeeg==1] <- 1
```

## Split age into bins

We use the age categories referred to in Marson et al 2005.
```{r}
mess$agecat <- cut(mess$ager,c(-1,5,9,19,29,39,49,59,69,100))
```

## Transform some variables

We plotted histograms of each (non-binary) variable we were considering including. The variables `nseiz` and `period` are highly positively-skewed. This is not surprising since it is a study on early epilepsy, so most subjects have only had one seizure and the frist seizure was not long before entering the study.
```{r}
par(mfrow=c(2,2))
hist(mess$intseiz1, breaks=20)
hist(mess$ager, breaks=20)
hist(mess$nseiz, breaks=20) #this one should be transformed
hist(mess$period, breaks=20) #and this one
```
We will try transforming `period` and `nseiz`. For `nseiz`, we simply use the indicator of whether it is 1 or more than 1, since over half of the patients have `nseiz==1`. We take the logarithm of `period` to reduce the skew.
```{r}
#par(mfrow=c(1,2))
mess$period.tr <- log(mess$period + 1)
mess$nseiz.tr <- mess$nseiz > 1
hist(mess$period.tr, breaks = 20)
#hist(mess$nseiz.tr)
```

## Select initial set of covariates

For the purposes of the initial exploratory model fitting, we use a small subset of the covariates. We address the issue of variable selection later on.

We drop all of the date variables because we suspect the absolute time does not matter; relative times are available for many of the events. We also drop the sub-categories for different types of seizures, retaining just the number of tonic-clonic seizures (the most severe type) and the overall number of seizures. We also drop the sub-categories of EEG abnormality, retaining just the overall indicator. We do not include the centre, since there are so many levels it adds too many degrees of freedom, and we have no information about how they might be grouped e.g. geographically.
```{r}
library(dplyr)
covars1 <- transmute(mess, ager, sex, trt, ntc, nseiz.tr, period.tr, eeg, abeeg)
```


# Check balance of randomisation

We check that the randomisation is balanced over sex and age. There is a noticeable deviation from an even split in some categories, but nothing too major.
```{r}
par(mfrow=c(1,2))

t.sex <- table(mess$sex,mess$trt)
colnames(t.sex)<-c('immediate','deferred')
rownames(t.sex)<-c('male','female')
plot(t.sex, main="randomisation by sex", ylab="treatment")
mtext("sex",3)
text(0.25,0.75,t.sex[1,1])
text(0.75,0.75,t.sex[2,1])
text(0.25,0.25,t.sex[1,2])
text(0.75,0.25,t.sex[2,2])

t.age <- table(mess$agecat, mess$trt)
colnames(t.age)<-c('immediate','deferred')
plot(t.age, main="randomisation by age", ylab="treatment")
mtext("age",3)
```


# Exploratory Kaplan-Meier curves

We plot Kaplan-Meier curves of the first seizure after randomization, grouped by treatment and sex. The first plot shows that the survival probability for those who received a deferred treatment is lower than for those immediately treated, at least for the first 5 years after the randomization. From the second plot it seems that sex does not have a significant effect on the survival probability.
```{r}
surv1 <- with(mess, Surv(intseiz1, indseiz1 == 1))
mfit <- survfit(surv1 ~ 1, conf.type = "log-log", data = mess)
#options(survfit.print.mean =T)
#plot(mfit, mark.time=T, xlab =factor(c(1,1)) "Days since randomization",ylab = "Survival")
#summary(mfit,censored=T)
par(mfrow=c(1,2))
mfit.trt <- survfit(surv1 ~ trt, conf.type = "log-log", data = mess)
plot(mfit.trt, conf.int = T, mark.time=F, col = 2:3, xlab = "Days since randomization", ylab = "Survival")
legend("topright", legend = c("Immediate","Deferred"), col = 2:3, lty=1)
mfit.sex <- survfit(surv1 ~ sex, conf.type = "log-log", data = mess)
plot(mfit.sex, conf.int = T, mark.time=F, col = c("orange","brown"), xlab = "Days since randomization",ylab = "Survival")
legend("topright", legend = c("Male","Female"), col = c("orange","brown"), lty=1)

#lfit <- survreg(surv1 ~ trt, data=mess)
#pct <- 1:98/100   # The 100th percentile of predicted survival is at +infinity
#ptime <- predict(lfit, newdata=mess, type='quantile',p=pct, se=TRUE)
#matplot(ptime$fit, 1-pct,xlab="Months", ylab="Survival", type='l', lty=c(1,2,2), col=1)
```


# Cox proportional hazards model

The Cox model relies on the strong assumption of *proportional hazards*, that is that a unit increase in a certain covariate has a multiplicative effect on the hazard rate. In particular, the hazard function $\lambda$ has the form
$$\lambda(t|X) = \lambda_0(t)\exp{X^T \beta}$$
where $X$ is the matrix of covariates and $\beta$ is the vector of coefficients to be estimated.

First we fit a naive proportional hazards model with the covariates of interest. We see that the treatment `trt` is significant, as is the number `nseiz` of seizures prior to entering the study. This is to be expected since subjects with a tendency for more frequent seizures are likely to go less time before the first post-randomisation seizure regardless of treatment. The elapsed time between the subject's first seizure and their entry into the trial is slightly significant, which is also unsurprising.
```{r}
mycox <- coxph(Surv(mess$intseiz1,mess$indseiz1,type="right") ~ trt + ager + sex + nseiz + period, data=mess)
summary(mycox)
```
Next we assess whether proportional hazards is a suitable assumption for these data. We see from the residual plots that the treatment seems to have a decreasing effect over time, but the residuals of the other covariates don't seem to vary over time. This is confirmed by the small p-value for `trt` in the test of the proportional hazards assumption. The treatment effect decreasing over time is indicative that a proportional hazards model is not suitable, but we will try a few fixes now.
```{r}
cox.zph(mycox)
par(mfrow=c(3,2))
plot(cox.zph(mycox))
```

We try adding into the model an interaction term of treatment with time. We see, as expected, that the interaction term is very significant. However the proportional hazards model is still rejected, so even with the interaction term we see that the Cox proportional hazards model is not suitable.
```{r}
mycox2 <- coxph(Surv(mess$intseiz1,mess$indseiz1,type="right") ~ trt + ager + sex + nseiz + period + trt:intseiz1, data=mess)
summary(mycox2)
cox.zph(mycox2)
```

Next we will fit the model using the transformed versions of `period` and `nseiz`. The significant covariates are pretty much the same as in the first model, however the assumption of proportional hazards is not supported in the `trt` and `nseiz` terms.
```{r}
mycox3 <- coxph(Surv(mess$intseiz1,mess$indseiz1,type="right") ~ trt + ager + sex + nseiz.tr + period.tr, data=mess)
summary(mycox3)
cox.zph(mycox3)
```

Finally, we will include an interaction term between `trt` and `nseiz`, since it is plausible that the treatment may have a different effect on people who suffer more severely (indicated by having had more seizures). With this model the proportional hazards assumption seems to be satisfied. However, the interaction term is only slightly significant, and including the interaction reduces the estimated treatment effect.
```{r}
mycox4 <- coxph(Surv(mess$intseiz1,mess$indseiz1,type="right") ~ trt + ager + sex + nseiz.tr + period.tr + trt:nseiz.tr, data=mess)
summary(mycox4)
cox.zph(mycox4)
```


# Aalen's additive model

```{r}
modaalen<-aalen(surv1 ~ trt + const(ager) + const(sex) + const(nseiz) + const(period) + const(abeeg), data = mess , n.sim=100)
summary(modaalen)
#par(mfrow=c(3,3))
plot(modaalen)
modaalen2<-aalen(surv1 ~ trt + const(ager) + sex + nseiz.tr + period.tr + abeeg , data = mess , n.sim=100)
#modaalen3<-aalen(surv1 ~ . - ager + const(ager), data = covars , n.sim=100)
x11()
plot(modaalen2)
dev.off()
#plot(modaalen2)
```


# Parametric survival models

```{r}
modpar1 <- survreg(surv1 ~ trt + ager + sex + nseiz + period + abeeg, mess, dist="exponential")
#summary(modpar1)
modpar2 <- survreg(surv1 ~ trt + ager + sex + nseiz + period + abeeg, mess, dist="weibull")
#summary(modpar2)
modpar3 <- survreg(surv1 ~ trt + ager + sex + nseiz + period + abeeg, mess, dist="lognormal")
#summary(modpar3)
modpar4 <- survreg(surv1 ~ trt + ager + sex + nseiz + period + abeeg, mess, dist="loglogistic")
#summary(modpar4)

# modpar1 <- flexsurvreg(surv1 ~ trt + ager + sex + nseiz + period, data = mess, dist="weibull")
# summary(modpar1)
# modpar2 <- flexsurvreg(surv1 ~ trt + ager + sex + nseiz + period, data = mess, dist="lnorm")
# summary(modpar2)
# modpar3 <- flexsurvreg(surv1 ~ trt + ager + sex + nseiz + period, data = mess, dist="llogis")
# summary(modpar3)
# modpar5 <- flexsurvreg(surv1 ~ trt + ager + sex + nseiz + period, data = mess, dist="gengamma")
# summary(modpar5)

parmodels<-matrix(NA,nrow=4,ncol=4)
parmodels[1,] <- c(summary(modpar1)$n, modpar1$loglik[1],summary(modpar1)$df, AIC(modpar1))
parmodels[2,] <- c(summary(modpar2)$n, modpar2$loglik[1],summary(modpar2)$df, AIC(modpar2))
parmodels[3,] <- c(summary(modpar3)$n, modpar3$loglik[1],summary(modpar3)$df, AIC(modpar3))
parmodels[4,] <- c(summary(modpar4)$n, modpar4$loglik[1],summary(modpar4)$df, AIC(modpar4))
colnames(parmodels) <- c("N.obs","Loglik","df","AIC")
rownames(parmodels) <- c("exponential","weibull","lognormal","loglogistic")
parmodels
```

Among the accelerated failure time (AFT) models, lognormal model is preferred.

```{r}
summary(modpar3)

# pct <- 1:98/100   # The 100th percentile of predicted survival is at +infinity
# ptime <- predict(modpar2, newdata=data.frame(trt=0,ager=24,sex=0,nseiz=1,period= 438.4), type='quantile',p=pct, se=TRUE)
# matplot(cbind(ptime$fit, ptime$fit + 2*ptime$se.fit, ptime$fit - 2*ptime$se.fit)/30.5, 1-pct,xlab="Months", ylab="Survival", type='l', lty=c(1,2,2), col=1)
```
Now let us consider the transformed variables.

```{r}
modpar1.tr <- survreg(surv1 ~ trt + scale(ager,scale = F) + sex + nseiz.tr + period.tr + abeeg, mess, dist="exponential")
modpar2.tr <- survreg(surv1 ~ trt + scale(ager,scale = F) + sex + nseiz.tr + period.tr + abeeg, mess, dist="weibull")
modpar3.tr <- survreg(surv1 ~ trt + scale(ager,scale = F) + sex + nseiz.tr + period.tr + abeeg, mess, dist="lognormal")
modpar4.tr <- survreg(surv1 ~ trt + scale(ager,scale = F) + sex + nseiz.tr + period.tr + abeeg, mess, dist="loglogistic")

parmodels.tr<-matrix(NA,nrow=4,ncol=4)
parmodels.tr[1,] <- c(summary(modpar1.tr)$n, modpar1.tr$loglik[1],summary(modpar1.tr)$df, AIC(modpar1.tr))
parmodels.tr[2,] <- c(summary(modpar2.tr)$n, modpar2.tr$loglik[1],summary(modpar2.tr)$df, AIC(modpar2.tr))
parmodels.tr[3,] <- c(summary(modpar3.tr)$n, modpar3.tr$loglik[1],summary(modpar3.tr)$df, AIC(modpar3.tr))
parmodels.tr[4,] <- c(summary(modpar4.tr)$n, modpar4.tr$loglik[1],summary(modpar4.tr)$df, AIC(modpar4.tr))
colnames(parmodels.tr) <- c("N.obs","Loglik","df","AIC")
rownames(parmodels.tr) <- c("exponential","weibull","lognormal","loglogistic")  
parmodels.tr #the difference to be interpreted in terms of chisq(1) = 3.84 

modpar.logn <- survreg(surv1 ~ . + trt:nseiz.tr - centre , covars, dist="lognormal") #using covars before it is defined... or is it covars1?
```

```{r}
covars <- transmute(mess, ager, sex, trt, nsp, ncp, nps, nmyo, nab, naab, ntc, noth, nseiz.tr, period.tr, eeg, abeeg, nsab, gparsp, gparnsp, fparsp, fparnsp, swab)
###DFNEW NOT WORKING!
dfNew <- data.frame(sex=factor(c(0,0)), trt=factor(c(0,1)),ager=84,nseiz.tr=factor(c(1,1)),period.tr = 3.4, abeeg = factor(c(1,1)))
percs <- (1:99)/100
FLogN <- predict(modpar3.tr, newdata=dfNew, type="quantile", p=percs, se=TRUE)
matplot(cbind(FLogN$fit[1, ],
              FLogN$fit[1, ] - 2*FLogN$se.fit[1, ],
              FLogN$fit[1, ] + 2*FLogN$se.fit[1, ])/365.25, 1-percs,
        type="l", main=expression(paste("LogNormal-Fit ", hat(S)(t), " with SE")),xlim = c(0,10),
        xlab="Time (in years)", ylab="Survival", lty=c(1, 2, 2), lwd=2, col="blue")
matlines(cbind(FLogN$fit[2, ],
               FLogN$fit[2, ] - 2*FLogN$se.fit[2, ],
               FLogN$fit[2, ] + 2*FLogN$se.fit[2, ])/365.25, 1-percs, col="red", lwd=2)
legend(x="topright", lwd=2, lty=c(1, 2, 1, 2), col=c("blue", "blue", "red", "red"),
       legend=c("Trt 1 (immediate)", "+- 2*SE", "Trt 0 (deferred)", "+- 2*SE"))
```


# Survival Lasso
```{r}

# 
# XX <- model.matrix(Surv(mess$intseiz1, mess$indseiz1, type="right") ~ ager + sex + trt + nsp + ncp + nps + nmyo + nab + naab + ntc + noth + nseiz.tr + period.tr + eeg + abeeg + nsab + gparsp + gparnsp + fparsp + fparnsp + swab, data=mess)
# 
# YY=Surv(mess$intseiz1, mess$indseiz1, type="right")
# YY <- YY[complete.cases(covars),] #remove rows with missing values (there are only 5/1425)
# 
# mynet <- glmnet(x=XX, y=YY, family="cox")
# mycvnet <- cv.glmnet(x=XX, y=YY, family="cox")
# 
# plot_glmnet(mynet, s=mycvnet$lambda.min)
```



# Random survival forests

We would like to ensure that the set of covariates we include in the model is relatively stable. Up to now we have only selected covariates insofar as the fitted log-normal model has some significant and some insignificant covariates. We now compare the set of significant covariates in the log-normal model to those obtained using a non-parametric variable selection technique, namely random survival forests.

Again we omit the `centre` variable since it destabilises the model, having a large number of levels many of which correspond to only one observation. If we had some additonal information say about suitably groupings of centres it would be sensible to include it. For instance, in Marson et al 2005 the authors distinguish between UK and non-UK centres. However we do not have any information linking the number of a centre to its location. However we now inlcude the counts of every type of seizure, and the results of all tests, as possible covariates. 

We still omit date variables. we found that the error rate didn't really decrease by creating more than 100-200 trees, so we use `ntree = 200`. There is not a universal threshold on the `vimp` above which variables should be considered selected, but in the literature `vimp=0.02` has been suggested as a rule-of-thumb.
```{r, cache=TRUE}
rsf.surv1<-rfsrc(Surv(intseiz1, indseiz1, type="right") ~ ager + sex + trt + nsp + ncp + nps + nmyo + nab + naab + ntc + noth + nseiz.tr + period.tr + eeg + abeeg + nsab + gparsp + gparnsp + fparsp + fparnsp + swab, data=mess, ntree = 200, importance=TRUE,  tree.err = T)

#print(rsf.surv1)
#plot(rsf.surv1)
gg_dta <- gg_vimp(rsf.surv1)
plot(gg_dta)
```

As we found in our exploratory analysis, `nseiz` and `trt` are the most important covariates, with `abeeg` also significant. We also see the counts of several particular types of seizure are important, which weren't included in our initial analysis.

The six most important variables in random forests were all significant in the log-normal model, which is encouraging. On the whole, random forests has selected roughly the same variables as the log-normal model, with only a few discrepancies. For instance, `nps` (one of the seizure counts) was significant in the log-normal model (p=0.009) but was certainly not selected by random forests.

For the purposes of our model, we will include only the covariates which the parametric and non-parametric approaches have both selected, namely `nseiz`, `trt`, `nsp`, `ncp`, `nmyo`, and `abeeg`. This captures the most important covariates of each approach.
